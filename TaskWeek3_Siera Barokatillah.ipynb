{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNOK9C6jOF601w5Zqmunkrb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Siera-Collab/TaskWeek2/blob/main/TaskWeek3_Siera%20Barokatillah.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Created by AssemblyAI**"
      ],
      "metadata": {
        "id": "4wi5rfNiwstL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Tensors**"
      ],
      "metadata": {
        "id": "T1xMfdhNw4k7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segala sesuatu di PyTorch didasarkan pada operasi Tensor. Tensor adalah matriks multidimensi yang berisi elemen-elemen dari satu tipe data:"
      ],
      "metadata": {
        "id": "J2rPwZA1xRTu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JasaTET7gc2t",
        "outputId": "84f936fe-af63-49c8-c829-1d536c4f1869"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "empty(1): tensor([4.5541e+36])\n",
            "empty(3): tensor([4.5377e+36, 3.1452e-41, 2.3410e+20])\n",
            "empty(2,3): tensor([[4.5894e+36, 3.1452e-41, 2.3410e+20],\n",
            "        [4.3639e-41, 4.4842e-44, 0.0000e+00]])\n",
            "empty(2, 2, 3): tensor([[[1.7673e+36, 3.1452e-41, 4.5893e+36],\n",
            "         [3.1452e-41, 1.5695e-43, 0.0000e+00]],\n",
            "\n",
            "        [[4.4842e-44, 0.0000e+00, 5.3367e-35],\n",
            "         [3.1445e-41, 0.0000e+00, 0.0000e+00]]])\n",
            "rand(5,3): tensor([[0.3310, 0.9650, 0.6974],\n",
            "        [0.5956, 0.8736, 0.0388],\n",
            "        [0.1903, 0.1959, 0.8452],\n",
            "        [0.0338, 0.5119, 0.8264],\n",
            "        [0.9636, 0.4484, 0.5662]])\n",
            "zeros(5,3): tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# torch.empty(size): uninitiallized\n",
        "x = torch.empty(1) # scalar\n",
        "print(\"empty(1):\", x)\n",
        "x = torch.empty(3) # vector\n",
        "print(\"empty(3):\",x)\n",
        "x = torch.empty(2, 3) # matrix\n",
        "print(\"empty(2,3):\",x)\n",
        "x = torch.empty(2, 2, 3) # tensor, 3 dimensions\n",
        "#x = torch.empty(2,2,2,3) # tensor, 4 dimensions\n",
        "print(\"empty(2, 2, 3):\",x)\n",
        "\n",
        "# torch.rand(size): random numbers [0, 1]\n",
        "x = torch.rand(5, 3)\n",
        "print(\"rand(5,3):\", x)\n",
        "\n",
        "# torch.zeros(size), fill with 0\n",
        "# torch.ones(size), fill with 1\n",
        "x = torch.zeros(5, 3)\n",
        "print(\"zeros(5,3):\", x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check size\n",
        "print(\"size\", x.size())  # x.size(0)\n",
        "print(\"shape\", x.shape)  # x.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLZd5RaTwsBN",
        "outputId": "48dda709-c475-43a0-c998-7b83e2899dc9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size torch.Size([5, 3])\n",
            "shape torch.Size([5, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check data type\n",
        "print(x.dtype)\n",
        "\n",
        "# specify types, float32 default\n",
        "x = torch.zeros(5, 3, dtype=torch.float16)\n",
        "print(x)\n",
        "\n",
        "# check type\n",
        "print(x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdUjqfxNxocD",
        "outputId": "60b4a59b-5612-4f5d-8394-9d3f2b47a4cd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], dtype=torch.float16)\n",
            "torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# construct from data\n",
        "x = torch.tensor([5.5, 3])\n",
        "print(x, x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28A-V6pkxsSF",
        "outputId": "d5010814-1e51-40bf-f56c-368a081b4b42"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.5000, 3.0000]) torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# argumen requires_grad\n",
        "# Ini akan memberi tahu pytorch bahwa nantinya akan perlu menghitung gradien untuk tensor ini\n",
        "# di langkah optimisasi Anda\n",
        "# yaitu, ini adalah variabel dalam model Anda yang ingin Anda optimalkan\n",
        "x = torch.tensor([5.5, 3], requires_grad=True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWX2zsBexvgA",
        "outputId": "13ef083d-65b6-47f7-bc51-8f4ba7e2ce7a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.5000, 3.0000], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Operations with Tensors**"
      ],
      "metadata": {
        "id": "_DpBcxkVzXm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Operations\n",
        "x = torch.ones(2, 2)\n",
        "y = torch.rand(2, 2)\n",
        "\n",
        "# elementwise addition\n",
        "z = x + y\n",
        "# torch.add(x,y)\n",
        "\n",
        "# penjumlahan in-place, segala sesuatu dengan tanda garis bawah di akhir adalah operasi in-place\n",
        "# yaitu, akan memodifikasi variabel tersebut\n",
        "# y.add_(x)\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRb7HkiNzZ1o",
        "outputId": "dd147d8c-f780-4d41-ca34-ac85d1c46a67"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[0.8953, 0.6534],\n",
            "        [0.6600, 0.5801]])\n",
            "tensor([[1.8953, 1.6534],\n",
            "        [1.6600, 1.5801]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# subtraction\n",
        "z = x - y\n",
        "z = torch.sub(x, y)\n",
        "\n",
        "# multiplication\n",
        "z = x * y\n",
        "z = torch.mul(x,y)\n",
        "\n",
        "# division\n",
        "z = x / y\n",
        "z = torch.div(x,y)"
      ],
      "metadata": {
        "id": "tjiP3OOuzgRw"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " slicing digunakan untuk mengambil bagian tertentu dari tensor (array multidimensi) berdasarkan baris dan kolom."
      ],
      "metadata": {
        "id": "8wy3ENFB4Kip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing\n",
        "x = torch.rand(5,3) # Membuat tensor acak dengan ukuran 5x3 (5 baris dan 3 kolom)\n",
        "print(x)\n",
        "print(\"x[:, 0]\", x[:, 0]) # all rows, column 0\n",
        "print(\"x[1, :]\", x[1, :]) # row 1, all columns\n",
        "print(\"x[1, 1]\", x[1,1]) # element at 1, 1\n",
        "\n",
        "# Get the actual value if only 1 element in your tensor\n",
        "print(\"x[1,1].item()\", x[1,1].item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4QsZIzX3tG5",
        "outputId": "7280f35b-5574-4811-8d9e-5db91662691c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0650, 0.1212, 0.7948],\n",
            "        [0.3658, 0.1853, 0.3387],\n",
            "        [0.6837, 0.2438, 0.4839],\n",
            "        [0.8054, 0.4621, 0.3206],\n",
            "        [0.2766, 0.0093, 0.5343]])\n",
            "x[:, 0] tensor([0.0650, 0.3658, 0.6837, 0.8054, 0.2766])\n",
            "x[1, :] tensor([0.3658, 0.1853, 0.3387])\n",
            "x[1, 1] tensor(0.1853)\n",
            "x[1,1].item() 0.18528860807418823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape with torch.view()\n",
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "# if -1 it pytorch will automatically determine the necessary size\n",
        "print(x.size(), y.size(), z.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opw5y4lF3wky",
        "outputId": "0d21bd15-941e-413e-9697-18384b5cf3e7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Numpy**"
      ],
      "metadata": {
        "id": "6UtplSOs4fKv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mengonversi Tensor Torch menjadi array NumPy dan sebaliknya sangatlah mudah."
      ],
      "metadata": {
        "id": "79qxmbbcUeVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(5)\n",
        "print(a)\n",
        "\n",
        "# torch to numpy with .numpy()\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(type(b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viQ9p7u24kug",
        "outputId": "89ab7c2a-b11a-43fa-ab04-8b153a046332"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fzP0TddUn5N",
        "outputId": "b6184006-6895-44e8-f8a6-af90252df90f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy to torch with .from_numpy(x), or torch.tensor() to copy it\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "c = torch.tensor(a)\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "\n",
        "# again be careful when modifying\n",
        "a += 1\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMoeT2-MU76a",
        "outputId": "4f08dc05-076b-4d65-8fe3-2e2111ac6bd9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GPU Support**"
      ],
      "metadata": {
        "id": "xvF8wdVWVA8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Secara default semua tensor dibuat di CPU. Namun, kita juga dapat memindahkannya ke GPU (jika tersedia), atau membuatnya langsung di GPU."
      ],
      "metadata": {
        "id": "t1z45KWAVIbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "x = torch.rand(2,2).to(device)  # move tensors to GPU device\n",
        "#x = x.to(\"cpu\")\n",
        "#x = x.to(\"cuda\")\n",
        "\n",
        "x = torch.rand(2,2, device=device)  # or directy create them on GPU"
      ],
      "metadata": {
        "id": "geLM6iJTVNAe"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Autograd**"
      ],
      "metadata": {
        "id": "Si93aVSyVT1_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paket autograd menyediakan diferensiasi otomatis untuk semua operasi pada Tensor. Secara umum, torch.autograd adalah mesin untuk menghitung produk vektor-Jacobian. Mesin ini menghitung turunan parsial sambil menerapkan aturan rantai.\n",
        "\n",
        "Tetapkan requires_grad = True:"
      ],
      "metadata": {
        "id": "o64E_BtZVZ05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# requires_grad = True -> tracks all operations on the tensor.\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "y = x + 2\n",
        "\n",
        "# y was created as a result of an operation, so it has a grad_fn attribute.\n",
        "# grad_fn: references a Function that has created the Tensor\n",
        "print(x) # created by the user -> grad_fn is None\n",
        "print(y)\n",
        "print(y.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUFTjAE2VRi9",
        "outputId": "8c30c296-8c62-4beb-ec34-b897bc0cd62e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.6700,  0.8968,  0.5947], requires_grad=True)\n",
            "tensor([0.3300, 2.8968, 2.5947], grad_fn=<AddBackward0>)\n",
            "<AddBackward0 object at 0x79a585c3eb00>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do more operations on y\n",
        "z = y * y * 3\n",
        "print(z)\n",
        "z = z.mean()\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBzr5bKeVjbZ",
        "outputId": "7dd2444c-a6dc-4e85-ef48-f8f0ce6be825"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.3268, 25.1735, 20.1975], grad_fn=<MulBackward0>)\n",
            "tensor(15.2326, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mari kita hitung gradien dengan backpropagation\n",
        "# Setelah selesai menghitung, kita dapat memanggil .backward() dan menghitung semua gradien secara otomatis.\n",
        "# Gradien untuk tensor ini akan diakumulasikan ke atribut .grad.\n",
        "\n",
        "# Ini adalah turunan parsial dari fungsi yang berkenaan dengan tensor\n",
        "\n",
        "print(x.grad)\n",
        "z.backward()\n",
        "print(x.grad) # dz/dx\n",
        "\n",
        "# !!! Careful!!! backward() accumulates the gradient for this tensor into .grad attribute.\n",
        "# !!! We need to be careful during optimization !!! optimizer.zero_grad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2G04CQqVnUf",
        "outputId": "44d39d63-3cec-4a73-c660-8dfb56c24ede"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "tensor([0.6601, 5.7935, 5.1894])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Stop a tensor trackong history**"
      ],
      "metadata": {
        "id": "e7j1JhL0WI-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example during the training loop when we want to update our weights, or after training during evaluation. These operations should not be part of the gradient computation. To prevent this, we can use:\n",
        "\n",
        "x.requires_grad_(False)\n",
        "x.detach()\n",
        "wrap in with torch.no_grad():"
      ],
      "metadata": {
        "id": "1rcqDObzWa8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# .requires_grad_(...) changes an existing flag in-place.\n",
        "a = torch.randn(2, 2)\n",
        "b = (a * a).sum()\n",
        "print(a.requires_grad)\n",
        "print(b.grad_fn)\n",
        "\n",
        "a.requires_grad_(True)\n",
        "b = (a * a).sum()\n",
        "print(a.requires_grad)\n",
        "print(b.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFhhDM_iWc4k",
        "outputId": "18b154d0-211d-4658-a2e8-eee0a8ae3b98"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "None\n",
            "True\n",
            "<SumBackward0 object at 0x79a571f29090>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .detach(): get a new Tensor with the same content but no gradient computation:\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "b = a.detach()\n",
        "print(a.requires_grad)\n",
        "print(b.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMCTJ2a7WmpF",
        "outputId": "827c7474-2a22-4970-ab13-ff439b74a653"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wrap in 'with torch.no_grad():'\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "print(a.requires_grad)\n",
        "with torch.no_grad():\n",
        "    b = a ** 2\n",
        "    print(b.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUwrCdWnW0de",
        "outputId": "bafcea67-34d6-4a20-a300-74edcdc54c8f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gradien Descent Autograd**"
      ],
      "metadata": {
        "id": "EzqaJFhYXGfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x  + b\n",
        "# here : f = 2 * x\n",
        "\n",
        "X = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8, 10, 12, 14, 16], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# model output\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "X_test = 5.0\n",
        "\n",
        "print(f'Prediction before training: f({X_test}) = {forward(X_test).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT-xvXOqW4yw",
        "outputId": "8877a745-a3f5-4f54-8f15-972159a9684f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5.0) = 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_epochs = 100\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # predict = forward pass\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    #w.data = w.data - learning_rate * w.grad\n",
        "    with torch.no_grad():\n",
        "      w -= learning_rate * w.grad\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    w.grad.zero_()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.3f}')\n",
        "\n",
        "print(f'Prediction after training: f({X_test}) = {forward(X_test).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXztxgSzXQxm",
        "outputId": "f44b6477-692f-40c5-ed31-3f7fa25eb475"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10: w = 1.998, loss = 0.000\n",
            "epoch 20: w = 2.000, loss = 0.000\n",
            "epoch 30: w = 2.000, loss = 0.000\n",
            "epoch 40: w = 2.000, loss = 0.000\n",
            "epoch 50: w = 2.000, loss = 0.000\n",
            "epoch 60: w = 2.000, loss = 0.000\n",
            "epoch 70: w = 2.000, loss = 0.000\n",
            "epoch 80: w = 2.000, loss = 0.000\n",
            "epoch 90: w = 2.000, loss = 0.000\n",
            "epoch 100: w = 2.000, loss = 0.000\n",
            "Prediction after training: f(5.0) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model, Loss & Optimizer**\n",
        "A typical PyTorch pipeline looks like this:\n",
        "\n",
        "\n",
        "Construct loss and optimizer\n",
        "Training loop:\n",
        "\n",
        "*   Design model (input, output, forward pass with different layers)\n",
        "*   Construct loss and optimizer\n",
        "\n",
        "\n",
        "Forward = compute prediction and loss\n",
        "Backward = compute gradients\n",
        "Update weights"
      ],
      "metadata": {
        "id": "WX80xZ6QWOtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x\n",
        "# here : f = 2 * x\n",
        "\n",
        "# 0) Training samples, watch the shape!\n",
        "X = torch.tensor([[1], [2], [3], [4], [5], [6], [7], [8]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8], [10], [12], [14], [16]], dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(f'n_samples = {n_samples}, n_features = {n_features}')\n",
        "\n",
        "# 0) create a test sample\n",
        "X_test = torch.tensor([5], dtype=torch.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABaK9PvDX5a_",
        "outputId": "96b403d6-bc32-4138-c439-c6d4d45ff3b3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_samples = 8, n_features = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design Model, the model has to implement the forward pass!\n",
        "\n",
        "# Here we could simply use a built-in model from PyTorch\n",
        "# model = nn.Linear(input_size, output_size)\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        # define different layers\n",
        "        self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)\n",
        "\n",
        "\n",
        "input_size, output_size = n_features, n_features\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "\n",
        "print(f'Prediction before training: f({X_test.item()}) = {model(X_test).item():.3f}')\n",
        "\n",
        "# 2) Define loss and optimizer\n",
        "learning_rate = 0.01\n",
        "n_epochs = 100\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(n_epochs):\n",
        "    # predict = forward pass with our model\n",
        "    y_predicted = model(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_predicted)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        w, b = model.parameters() # unpack parameters\n",
        "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l.item())\n",
        "\n",
        "print(f'Prediction after training: f({X_test.item()}) = {model(X_test).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2xZ-F9aX_Fg",
        "outputId": "e93f52f9-c6a1-483b-82c9-8dbcf8cb05cd"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5.0) = 2.345\n",
            "epoch  10 : w =  2.0810155868530273  loss =  0.04405258223414421\n",
            "epoch  20 : w =  2.078645706176758  loss =  0.04058663547039032\n",
            "epoch  30 : w =  2.0755622386932373  loss =  0.03746597096323967\n",
            "epoch  40 : w =  2.072599172592163  loss =  0.034585222601890564\n",
            "epoch  50 : w =  2.0697522163391113  loss =  0.03192593902349472\n",
            "epoch  60 : w =  2.067017078399658  loss =  0.029471158981323242\n",
            "epoch  70 : w =  2.0643889904022217  loss =  0.02720516175031662\n",
            "epoch  80 : w =  2.061864137649536  loss =  0.025113413110375404\n",
            "epoch  90 : w =  2.0594382286071777  loss =  0.02318238653242588\n",
            "epoch  100 : w =  2.057107448577881  loss =  0.021399881690740585\n",
            "Prediction after training: f(5.0) = 9.964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. First Neural Net**\n",
        "GPU, Datasets, DataLoader, Transforms, Neural Net, Training & Evaluation"
      ],
      "metadata": {
        "id": "8j3Mha3VYP7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = examples.next()\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "K0U6w__tYFgZ",
        "outputId": "10a18454-afe8-40ba-dd56-a14664b1e807"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'_SingleProcessDataLoaderIter' object has no attribute 'next'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-49894ba40db1>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mexample_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_SingleProcessDataLoaderIter' object has no attribute 'next'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QkkAQ5NyY3g3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass and loss calculation\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udJ5RnoDrOzp",
        "outputId": "b279da5d-1adf-4ea5-ebba-406403d222fe"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Step [100/600], Loss: 0.3120\n",
            "Epoch [1/2], Step [200/600], Loss: 0.1933\n",
            "Epoch [1/2], Step [300/600], Loss: 0.2352\n",
            "Epoch [1/2], Step [400/600], Loss: 0.0781\n",
            "Epoch [1/2], Step [500/600], Loss: 0.2208\n",
            "Epoch [1/2], Step [600/600], Loss: 0.1340\n",
            "Epoch [2/2], Step [100/600], Loss: 0.2127\n",
            "Epoch [2/2], Step [200/600], Loss: 0.1407\n",
            "Epoch [2/2], Step [300/600], Loss: 0.0869\n",
            "Epoch [2/2], Step [400/600], Loss: 0.0369\n",
            "Epoch [2/2], Step [500/600], Loss: 0.0740\n",
            "Epoch [2/2], Step [600/600], Loss: 0.0950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model: we don't need to compute gradients\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = len(test_loader.dataset)\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        # max returns (output_value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the {n_samples} test images: {100*acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9x54JYIrTUd",
        "outputId": "e8842208-bcb4-4122-9cd9-2adac300ed26"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 97.1 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. CNN**\n",
        "\n",
        "This section covers:\n",
        "\n",
        "- Convolutional Layers\n",
        "- MaxPooling\n",
        "- Save/Load model"
      ],
      "metadata": {
        "id": "NSpFHDm7ZEcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "\n",
        "# dataset has PILImage images of range [0, 1].\n",
        "# We transform them to Tensors of normalized range [-1, 1]\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def imshow(imgs):\n",
        "    imgs = imgs / 2 + 0.5   # unnormalize\n",
        "    npimgs = imgs.numpy()\n",
        "    plt.imshow(np.transpose(npimgs, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# one batch of random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "img_grid = torchvision.utils.make_grid(images[0:25], nrow=5)\n",
        "imshow(img_grid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "DCYej_ZCZN7n",
        "outputId": "adf4efc0-d61a-46ba-f107-255a99461791"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12404773.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'_SingleProcessDataLoaderIter' object has no attribute 'next'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-6f33ecfa8f76>\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# one batch of random training images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mimg_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_SingleProcessDataLoaderIter' object has no attribute 'next'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3XFl4e6VZVYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
        "        self.fc1 = nn.Linear(64*4*4, 64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # N, 3, 32, 32\n",
        "        x = F.relu(self.conv1(x))   # -> N, 32, 30, 30\n",
        "        x = self.pool(x)            # -> N, 32, 15, 15\n",
        "        x = F.relu(self.conv2(x))   # -> N, 64, 13, 13\n",
        "        x = self.pool(x)            # -> N, 64, 6, 6\n",
        "        x = F.relu(self.conv3(x))   # -> N, 64, 4, 4\n",
        "        x = torch.flatten(x, 1)     # -> N, 1024\n",
        "        x = F.relu(self.fc1(x))     # -> N, 64\n",
        "        x = self.fc2(x)             # -> N, 10\n",
        "        return x\n",
        "\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'[{epoch + 1}] loss: {running_loss / n_total_steps:.3f}')\n",
        "\n",
        "print('Finished Training')\n",
        "PATH = './cnn.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "n4ekV872wPF5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab1d2aaa-2944-473e-9ca4-18996969f5d0"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] loss: 1.490\n",
            "[2] loss: 1.109\n",
            "[3] loss: 0.949\n",
            "[4] loss: 0.843\n",
            "[5] loss: 0.772\n",
            "[6] loss: 0.710\n",
            "[7] loss: 0.659\n",
            "[8] loss: 0.617\n",
            "[9] loss: 0.578\n",
            "[10] loss: 0.543\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "509pgWoXZdgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = ConvNet()\n",
        "loaded_model.load_state_dict(torch.load(PATH)) # it takes the loaded dictionary, not the path file itself\n",
        "loaded_model.to(device)\n",
        "loaded_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_correct2 = 0\n",
        "    n_samples = len(test_loader.dataset)\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        outputs2 = loaded_model(images)\n",
        "        _, predicted2 = torch.max(outputs2, 1)\n",
        "        n_correct2 += (predicted2 == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the model: {acc} %')\n",
        "\n",
        "    acc = 100.0 * n_correct2 / n_samples\n",
        "    print(f'Accuracy of the loaded model: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVIQkMQXsRIR",
        "outputId": "263e9659-8815-4fb0-d78f-889af7327a4d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-66-edd86cdeb3ea>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model.load_state_dict(torch.load(PATH)) # it takes the loaded dictionary, not the path file itself\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model: 73.01 %\n",
            "Accuracy of the loaded model: 73.01 %\n"
          ]
        }
      ]
    }
  ]
}